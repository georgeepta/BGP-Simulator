import csv
import json
import psycopg2
import requests
import operator


class NestedDict(dict):
    def __missing__(self, key):
        value = self[key] = type(self)()
        return value

def read_json_data(file_path):
    try:
        with open(file_path, 'r') as json_file:
            data = json.load(json_file)
            return data
    except FileNotFoundError:
        print("Sorry, the file, "+ file_path + " ,does not exist.")
        return 0

def write_results(as_country_vuln_results_dict, file_path):
    with open(file_path, 'w') as json_file:
        json.dump(as_country_vuln_results_dict, json_file)


def connect_to_db(db_name, user, password, host, port):
    # establishing the connection
    conn = psycopg2.connect(
        database=db_name, user=user, password=password, host=host, port=port
    )

    '''
    psycopg2 is Python DB API-compliant, so the auto-commit feature is off by default. 
    We need to set conn.autocommit to True to commit any pending transaction to the database.
    '''
    conn.autocommit = True

    return conn


def fetch_sim_uuids_using_timestamps(conn, from_start_timestamp, to_start_timestamp):
    # Creating a cursor object using the cursor() method
    cursor = conn.cursor()

    # Retrieving data
    cursor.execute("SELECT simulation_id FROM BGP_HIJACKING_SIMULATIONS WHERE sim_start_time >= %s and sim_start_time <= %s", (from_start_timestamp, to_start_timestamp))

    # return all rows from the table as json array
    return [r[0] for r in cursor.fetchall()]


def fetch_AS_details(conn):
    # Creating a cursor object using the cursor() method
    cursor = conn.cursor()
    sql = '''SELECT * FROM ASN_TO_ORG''';
    cursor.execute(sql)
    result = cursor.fetchall()
    asns_details_dict = {}
    for row in result:
        asns_details_dict[row[0]] = row[1]
    return asns_details_dict


def compute_num_of_all_sims(conn):
    # Creating a cursor object using the cursor() method
    cursor = conn.cursor()

    # Retrieving data
    cursor.execute("SELECT num_of_simulations, num_of_repetitions FROM BGP_HIJACKING_SIMULATIONS WHERE simulation_data->>'simulation_type' = 'random'")
    return sum([r[0]*r[1] for r in cursor.fetchall()])



def generate_as_vuln_result(as_country_vuln_results_dict, all_sim_uuids):
    as_country_vuln_results_dict["as_vuln_ranking"] = {}
    for simulation_id in all_sim_uuids:
        response = requests.post('http://127.0.0.1:5000/as_vulnerability_ranking', json={"simulation_uuid": simulation_id})
        #print(response.json())
        json_response = response.json()

        for AS in json_response["as_vuln_ranking"]:
            if AS not in as_country_vuln_results_dict["as_vuln_ranking"]:
                as_country_vuln_results_dict["as_vuln_ranking"][AS] = [json_response["as_vuln_ranking"][AS]]
            else:
                as_country_vuln_results_dict["as_vuln_ranking"][AS].append(json_response["as_vuln_ranking"][AS])

    as_vuln_ranking = dict(map(lambda x: (x[0], (sum(x[1]) / len(all_sim_uuids))), as_country_vuln_results_dict["as_vuln_ranking"].items()))
    as_country_vuln_results_dict["as_vuln_ranking"] = dict(sorted(as_vuln_ranking.items(), key=operator.itemgetter(1), reverse=True))

    return as_country_vuln_results_dict


def generate_country_vuln_result(as_country_vuln_results_dict, asns_details_dict, count_of_infected_ASes_per_country):
    Country_percentage_dict = {}

    for AS in as_country_vuln_results_dict["as_vuln_ranking"]:
        if int(AS) in asns_details_dict:
            country = asns_details_dict[int(AS)]["organizationDetails"]["country"]
            if country in Country_percentage_dict:
                Country_percentage_dict[country].append(as_country_vuln_results_dict["as_vuln_ranking"][AS])
            else:
                Country_percentage_dict[country] = [as_country_vuln_results_dict["as_vuln_ranking"][AS]]

    if count_of_infected_ASes_per_country:
        country_vuln_ranking = dict(map(lambda x: (x[0], ((sum(x[1]) / len(x[1])) + (len(x[1]) / len(as_country_vuln_results_dict["as_vuln_ranking"])) * 100) / 2), Country_percentage_dict.items()))
    else:
        country_vuln_ranking = dict(map(lambda x: (x[0], sum(x[1]) / len(x[1])), Country_percentage_dict.items()))

    as_country_vuln_results_dict["country_vuln_ranking"] = dict(sorted(country_vuln_ranking.items(), key=operator.itemgetter(1), reverse=True))



def write_as_vuln_ranking_details_to_csv(as_country_vuln_results_dict, asns_details_dict):
    with open('as_ranking.csv', 'w') as outfile:
        writer = csv.writer(outfile)
        writer.writerow(["ASN", "AS_Name", "Organization_Name", "Country", "RIR", "Ranking_Score"])
        for AS, score in as_country_vuln_results_dict["as_vuln_ranking"].items():
            if int(AS) in asns_details_dict:
                as_name = asns_details_dict[int(AS)]["name"] if "name" in asns_details_dict[int(AS)] else ""
                org_name = asns_details_dict[int(AS)]["organizationDetails"]["name"] if "name" in asns_details_dict[int(AS)]["organizationDetails"] else ""
                country_code = asns_details_dict[int(AS)]["organizationDetails"]["country"] if "country" in asns_details_dict[int(AS)]["organizationDetails"] else ""
                rir_name = asns_details_dict[int(AS)]["source"] if "source" in asns_details_dict[int(AS)] else ""
                writer.writerow([
                    AS,
                    as_name,
                    org_name,
                    country_code,
                    rir_name,
                    score
                ])
            else:
                writer.writerow([
                    AS,
                    "",
                    "",
                    "",
                    "",
                    score
                ])


def write_country_vuln_ranking_details_to_csv(as_country_vuln_results_dict):
    with open('country_ranking.csv', 'w') as outfile:
        writer = csv.writer(outfile)
        writer.writerow(["Country", "Ranking_Score"])
        for key, value in as_country_vuln_results_dict["country_vuln_ranking"].items():
            writer.writerow([key, value])


if __name__ == '__main__':
    '''
    create a connection to the database
    '''
    conn = connect_to_db("bgp_simulator", 'gepta', '1821', '127.0.0.1', '5432')

    all_sim_uuids = []
    timestamps_list = [('2022-05-05T16:38:54.981295+03:00', '2022-05-10T01:13:19.918058+03:00')]
    for timestamp_tuple in timestamps_list:
        all_sim_uuids += fetch_sim_uuids_using_timestamps(conn, timestamp_tuple[0], timestamp_tuple[1])

    print(all_sim_uuids)
    asns_details_dict = fetch_AS_details(conn)

    as_country_vuln_results_dict = NestedDict()
    generate_as_vuln_result(as_country_vuln_results_dict, all_sim_uuids)
    generate_country_vuln_result(as_country_vuln_results_dict, asns_details_dict, True)
    print(as_country_vuln_results_dict)
    as_country_vuln_results_dict["num_of_all_sims"] = len(all_sim_uuids)
    write_results(as_country_vuln_results_dict, "as_country_vuln_ranking.json")

    json_data = read_json_data(r'as_country_vuln_ranking.json')
    write_as_vuln_ranking_details_to_csv(json_data, asns_details_dict)
    write_country_vuln_ranking_details_to_csv(json_data)

    '''
    close connection to database
    '''
    conn.close()